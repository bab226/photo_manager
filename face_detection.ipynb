{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face detection Notebook Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mJupyter Server crashed. Unable to connect. \n",
      "\u001b[1;31mError code from Jupyter: 1\n",
      "\u001b[1;31mTraceback (most recent call last):\n",
      "\u001b[1;31m  File \"/opt/anaconda3/lib/python3.8/site-packages/notebook/traittypes.py\", line 235, in _resolve_classes\n",
      "\u001b[1;31m    klass = self._resolve_string(klass)\n",
      "\u001b[1;31m  File \"/opt/anaconda3/lib/python3.8/site-packages/traitlets/traitlets.py\", line 2015, in _resolve_string\n",
      "\u001b[1;31m    return import_item(string)\n",
      "\u001b[1;31m  File \"/opt/anaconda3/lib/python3.8/site-packages/traitlets/utils/importstring.py\", line 33, in import_item\n",
      "\u001b[1;31m    module = __import__(package, fromlist=[obj])\n",
      "\u001b[1;31mModuleNotFoundError: No module named 'jupyter_server.contents'\n",
      "\u001b[1;31m\n",
      "\u001b[1;31mDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31m\n",
      "\u001b[1;31mTraceback (most recent call last):\n",
      "\u001b[1;31m  File \"/opt/anaconda3/bin/jupyter-notebook\", line 11, in <module>\n",
      "\u001b[1;31m    sys.exit(main())\n",
      "\u001b[1;31m  File \"/opt/anaconda3/lib/python3.8/site-packages/jupyter_core/application.py\", line 283, in launch_instance\n",
      "\u001b[1;31m    super().launch_instance(argv=argv, **kwargs)\n",
      "\u001b[1;31m  File \"/opt/anaconda3/lib/python3.8/site-packages/traitlets/config/application.py\", line 1073, in launch_instance\n",
      "\u001b[1;31m    app = cls.instance(**kwargs)\n",
      "\u001b[1;31m  File \"/opt/anaconda3/lib/python3.8/site-packages/traitlets/config/configurable.py\", line 583, in instance\n",
      "\u001b[1;31m    inst = cls(*args, **kwargs)\n",
      "\u001b[1;31m  File \"/opt/anaconda3/lib/python3.8/site-packages/traitlets/traitlets.py\", line 1292, in __new__\n",
      "\u001b[1;31m    inst.setup_instance(*args, **kwargs)\n",
      "\u001b[1;31m  File \"/opt/anaconda3/lib/python3.8/site-packages/traitlets/traitlets.py\", line 1335, in setup_instance\n",
      "\u001b[1;31m    super(HasTraits, self).setup_instance(*args, **kwargs)\n",
      "\u001b[1;31m  File \"/opt/anaconda3/lib/python3.8/site-packages/traitlets/traitlets.py\", line 1311, in setup_instance\n",
      "\u001b[1;31m    init(self)\n",
      "\u001b[1;31m  File \"/opt/anaconda3/lib/python3.8/site-packages/notebook/traittypes.py\", line 226, in instance_init\n",
      "\u001b[1;31m    self._resolve_classes()\n",
      "\u001b[1;31m  File \"/opt/anaconda3/lib/python3.8/site-packages/notebook/traittypes.py\", line 238, in _resolve_classes\n",
      "\u001b[1;31m    warn(f\"{klass} is not importable. Is it installed?\", ImportWarning)\n",
      "\u001b[1;31mTypeError: warn() missing 1 required keyword-only argument: 'stacklevel'. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import face_recognition\n",
    "import cv2\n",
    "from PIL import Image, ImageDraw \n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For troubleshooting purposes only.\n",
    "def detect_faces(image):\n",
    "    return face_recognition.face_locations(image, model='hog', number_of_times_to_upsample=2)  # Using CNN for better accuracy.\n",
    "def rotate_image(image, angle):\n",
    "    return image.rotate(angle, expand=True)\n",
    "\n",
    "def show_face_locations(image_path):\n",
    "    # Load the image file into a numpy array\n",
    "    image = face_recognition.load_image_file(image_path)\n",
    "    \n",
    "    # Convert the image to a PIL Image object\n",
    "    pil_image = Image.fromarray(image)\n",
    "    \n",
    "    # Detect faces at original orientation\n",
    "    face_locations = detect_faces(image)\n",
    "    \n",
    "    # If no faces, try rotating the image by 90, 180, 270 degrees\n",
    "    angles = [0, 90, 180, 270]\n",
    "    for angle in angles:\n",
    "        if face_locations:\n",
    "            break\n",
    "        rotated_image = rotate_image(pil_image, angle)\n",
    "        rotated_array = np.array(rotated_image)\n",
    "        face_locations = detect_faces(rotated_array)\n",
    "\n",
    "    # Draw rectangles around detected faces\n",
    "    draw = ImageDraw.Draw(pil_image)\n",
    "    for (top, right, bottom, left) in face_locations:\n",
    "        draw.rectangle([left, top, right, bottom], outline=\"red\", width=3)\n",
    "\n",
    "    # Display the image\n",
    "    pil_image.show()\n",
    "\n",
    "# First load your images and adjust contrast for better facial recognition.\n",
    "# Replace \"/Users/bab226/Pictures/test_photos/alex\" with your actual image directory\n",
    "directory = \"/Users/bab226/Pictures/test_photos/test_photos\"\n",
    "# Process each image in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "        image_path = os.path.join(directory, filename)\n",
    "        show_face_locations(image_path)\n",
    "#images_with_faces = load_and_process_images(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads images from a directory, detects faces, and encodes each face.\n",
    "\n",
    "def detect_faces(image):\n",
    "    return face_recognition.face_locations(image, model='hog', number_of_times_to_upsample=2)  # Using CNN for better accuracy.\n",
    "def rotate_image(image, angle):\n",
    "    return image.rotate(angle, expand=True)\n",
    "\n",
    "def tryVar(var):\n",
    "    try:\n",
    "        val = var\n",
    "    except NameError:\n",
    "        return None\n",
    "    return val\n",
    "\n",
    "def load_and_process_images(directory):\n",
    "    images_with_faces = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            image_path = os.path.join(directory, filename)  # Get file path\n",
    "            image = face_recognition.load_image_file(image_path)  # Load image\n",
    "            pil_image = Image.fromarray(image)\n",
    "            face_locations = detect_faces(image)  # Detect faces\n",
    "    \n",
    "            if face_locations:  # If face detected, append to list\n",
    "                print(\"Face detected\")\n",
    "            else:\n",
    "                # If no faces, try rotating the image by 90, 180, 270 degrees.\n",
    "                angles = [0, 90, 180, 270]\n",
    "                for angle in angles:\n",
    "                    if face_locations:\n",
    "                        print(\"Face detected\")\n",
    "                        break\n",
    "                    else:\n",
    "                        print(\"Face NOT detected. Trying again...\")\n",
    "                        rotated_image = rotate_image(pil_image, angle)\n",
    "                        rotated_array = np.array(rotated_image)\n",
    "                        face_locations = detect_faces(rotated_array)\n",
    "                    \n",
    "                print(\"Skipping...\")\n",
    "                \n",
    "            face_encodings = face_recognition.face_encodings(image, face_locations)\n",
    "            images_with_faces.append((image_path, image, face_locations, face_encodings))\n",
    "    return images_with_faces\n",
    "\n",
    "def extract_encodings_with_paths(images_with_faces):\n",
    "    encodings_with_paths = []\n",
    "    for item in images_with_faces:\n",
    "        image_path, _, _, face_encodings = item\n",
    "        for encoding in face_encodings:\n",
    "            encodings_with_paths.append((image_path, list(encoding)))  # Ensure encoding is a 1D list\n",
    "    return encodings_with_paths\n",
    "\n",
    "def cluster_faces_with_paths(encodings_with_paths, n_clusters):\n",
    "    encodings = [encoding for _, encoding in encodings_with_paths]\n",
    "    kmeans = KMeans(n_clusters=n_clusters)\n",
    "    labels = kmeans.fit_predict(encodings)\n",
    "    \n",
    "    clusters = {i: [] for i in range(n_clusters)}\n",
    "    for label, (image_path, _) in zip(labels, encodings_with_paths):\n",
    "        clusters[label].append(image_path)\n",
    "    \n",
    "    return clusters, labels\n",
    "\n",
    "def find_optimal_clusters(encodings, max_k):\n",
    "    \"\"\"Find optimal clusters using elbow method.\"\"\"\n",
    "    iters = range(1, max_k+1)\n",
    "    distortions = []\n",
    "    \n",
    "    for k in iters:\n",
    "        kmeans = KMeans(n_clusters=k)\n",
    "        kmeans.fit(encodings)\n",
    "        distortions.append(kmeans.inertia_)\n",
    "        \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(iters, distortions, marker='o')\n",
    "    plt.xlabel('Number of clusters')\n",
    "    plt.ylabel('Inertia')\n",
    "    plt.title('Elbow method for determining optimal number of clusters')\n",
    "    plt.show()\n",
    "\n",
    "def visualize_and_tag_clusters(clusters):\n",
    "    \"\"\"Displays images in each cluster and allows user to tag clusters.\n",
    "    Returns a dictionary of cluster IDs to tags.\"\"\"\n",
    "\n",
    "    cluster_tags = {}\n",
    "    for cluster_id, image_paths in clusters.items():\n",
    "        print(f\"Cluster {cluster_id}:\")\n",
    "        fig, axes = plt.subplots(1, len(image_paths), figsize=(20, 5))\n",
    "        \n",
    "        if len(image_paths) == 1:\n",
    "            axes = [axes]\n",
    "        \n",
    "        for ax, path in zip(axes, image_paths):\n",
    "            img = mpimg.imread(path)\n",
    "            ax.imshow(img)\n",
    "            ax.set_title(os.path.basename(path))\n",
    "            ax.axis('off')\n",
    "        \n",
    "        plt.show()\n",
    "        tag = input(f\"Provide a label for cluster {cluster_id}: \")\n",
    "        cluster_tags[cluster_id] = tag\n",
    "    \n",
    "    return cluster_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"/Users/bab226/Pictures/test_photos/test_photos\"\n",
    "images_with_faces = load_and_process_images(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpack encodings and labels from images_with_faces:\n",
    "encodings_with_paths = extract_encodings_with_paths(images_with_faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_encodings = [encoding for _, encoding in encodings_with_paths]\n",
    "find_optimal_clusters(all_encodings, max_k=2)  # Adjust max_k as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform clustering into the optimal number of clusters (e.g., replace 5 with the optimal number)\n",
    "optimal_clusters = 2  # Replace with the actual optimal number determined\n",
    "clusters, cluster_labels = cluster_faces_with_paths(encodings_with_paths, n_clusters=optimal_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize and tag clusters\n",
    "cluster_tags = visualize_and_tag_clusters(clusters)\n",
    "\n",
    "print(\"Cluster tags:\")\n",
    "for cluster_id, tag in cluster_tags.items():\n",
    "    print(f\"Cluster {cluster_id}: {tag}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from PIL import Image\n",
    "import piexif\n",
    "\n",
    "def save_tags_to_file(cluster_tags, file_path='cluster_tags.json'):\n",
    "    with open(file_path, 'w') as file:\n",
    "        json.dump(cluster_tags, file, indent=4)\n",
    "\n",
    "def add_tags_to_jpeg_images(clusters, cluster_tags):\n",
    "    \"\"\"Adds a tag to each JPEG image in the specified directory, using the cluster tags.\n",
    "    Saves the modified images with the tags.\n",
    "    Args:\n",
    "        clusters (dict): Dictionary of cluster IDs to image paths.\n",
    "        cluster_tags (dict): Dictionary of cluster IDs to tags.\"\"\"\n",
    "    for cluster_id, image_paths in clusters.items():\n",
    "        tag = cluster_tags.get(cluster_id, 'untagged')\n",
    "        for image_path in image_paths:\n",
    "            image = Image.open(image_path)\n",
    "            exif_dict = piexif.load(image.info['exif'])\n",
    "            exif_dict['Exif'][piexif.ExifIFD.UserComment] = tag.encode('utf-8')\n",
    "            exif_bytes = piexif.dump(exif_dict)\n",
    "            image.save(image_path, 'jpeg', exif=exif_bytes)\n",
    "            print(f\"Saved tag '{tag}' to image {image_path}\")\n",
    "\n",
    "def search_images_by_tag(directory, search_tag):\n",
    "    \"\"\"\n",
    "    Searches for JPEG images in the specified directory with the specified tag.\n",
    "    Returns a list of image paths that match the tag.\n",
    "    Args:\n",
    "        directory (str): Path to the directory containing JPEG images.\n",
    "        search_tag (str): Tag to search for in the images.\"\"\"\n",
    "\n",
    "    print(f\"Searching for images with tag '{search_tag}'...\")\n",
    "    print(\"Found:\")\n",
    "    \n",
    "    matching_images = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.jpg'):\n",
    "            image_path = os.path.join(directory, filename)\n",
    "            image = Image.open(image_path)\n",
    "            exif_dict = piexif.load(image.info['exif'])\n",
    "            user_comment = exif_dict['Exif'].get(piexif.ExifIFD.UserComment, b'').decode('utf-8')\n",
    "            if search_tag == user_comment:\n",
    "                matching_images.append(image_path)\n",
    "    return matching_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add tags to images\n",
    "add_tags_to_jpeg_images(clusters, cluster_tags)\n",
    "\n",
    "# Example verification with ExifTool\n",
    "# Open Terminal and use ExifTool to verify tags\n",
    "# exiftool -UserComment /path/to/your/image.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "directory = \"/Users/bab226/Pictures/test_photos/test_photos\"\n",
    "search_tag = 'alex'\n",
    "\n",
    "matching_images = search_images_by_tag(directory, search_tag)\n",
    "print(f\"Images with tag '{search_tag}':\")\n",
    "for image_path in matching_images:\n",
    "    print(image_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import helper_functions as hf\n",
    "\n",
    "# Main:\n",
    "directory = \"/Users/bab226/Pictures/test_photos/test_photos\"\n",
    "images_with_paths = hf.load_and_process_images(directory, 1.5)\n",
    "\n",
    "# Options\n",
    "kmax = len(images_with_paths)-1  # Maximum number of clusters to try\n",
    "\n",
    "# Unpack encodings and labels from images_with_faces:\n",
    "encodings_with_paths = hf.extract_encodings_with_paths(images_with_paths)\n",
    "all_encodings = [encoding for _, encoding in encodings_with_paths]\n",
    "\n",
    "# Find optimal cluster size.\n",
    "optimal_k = hf.find_optimal_cluster(all_encodings, max_k=kmax)\n",
    "print(f\"Optimal number of clusters: {optimal_k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
